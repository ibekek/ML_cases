{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ИМПОРТЫ"
      ],
      "metadata": {
        "id": "eIPZu4-c3MIO"
      },
      "id": "eIPZu4-c3MIO"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8XsPyewuM8G",
        "outputId": "0d520899-d473-4cce-d3ce-2c8b2d3dd594"
      },
      "id": "g8XsPyewuM8G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=a6b537b8c8b4b65a23ac39b160a71c3dba9f1783412f621f863eeae82d795dac\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd1f8da",
      "metadata": {
        "id": "7dd1f8da"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math as mt\n",
        "\n",
        "import datetime\n",
        "import warnings\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "# from optbinning import BinningProcess\n",
        "from datetime import datetime as dt\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "sns.set(style=\"darkgrid\", font_scale=1.4)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('display.max_columns', 100)\n",
        "\n",
        "# from libro.BruteFormater import BruteData as bf\n",
        "# from libro import LoadMaster as lm\n",
        "# from libro import EasyWorker as ew\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, RobustScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.metrics import roc_auc_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "from sklearn.ensemble import IsolationForest, RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn import metrics, model_selection\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import torch\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "# from torch.nn import functional as F\n",
        "# from torch.autograd import Variable\n",
        "# from torch import nn\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jjO1EfI6wBDX"
      },
      "id": "jjO1EfI6wBDX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b51c212",
      "metadata": {
        "id": "3b51c212"
      },
      "outputs": [],
      "source": [
        "model = ['audi', 'bmw', 'ford', 'hyundi', 'merc', 'skoda', 'toyota', 'vauxhall', 'vw']\n",
        "model_n = ['Audi', 'BMW', 'Ford', 'Hyundai', 'Mercedes', 'Skoda', 'Toyota', 'Opel', 'Volkswagen'] # Массив для переименования марок\n",
        "models = model.copy()\n",
        "# model = ['focus', 'cclass', unclean_cclass', 'unclean_focus']\n",
        "\n",
        "for i in range(len(model)): # загрузка данных\n",
        "    path = r'/content/drive/My Drive/ProjectPIVO/' + str(model[i]) + '.csv' \n",
        "    models[i] = pd.read_csv(path)\n",
        "    # Переименовываем марки автомобиля\n",
        "    models[i]['Brand'] = f'{model_n[i]}'\n",
        "    # Переименование колонок на Uppercase \n",
        "    models[i] = models[i].rename(columns = {'model' : 'Model', 'year' : 'Year', 'price' : 'Price', \n",
        "        'transmission' : 'Transmission', 'mileage' : 'Mileage', 'fuelType' : 'Fuel_Type', 'tax' : 'Tax', 'mpg' : 'MPG', \n",
        "        'engineSize' : 'Engine_Size', 'tax(£)' : 'Tax2'})\n",
        "all_models = pd.DataFrame() # Создание датафрэйма\n",
        "# Добавление содержимого всех csv файлов в общий датафрейм all_models\n",
        "for i in range(len(model)):\n",
        "    models[i]['Brand'] = f'{model_n[i]}' \n",
        "    all_models = pd.concat([all_models, models[i]]) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Первичная первичная обработка"
      ],
      "metadata": {
        "id": "LU1ey1VyEMzd"
      },
      "id": "LU1ey1VyEMzd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5547404",
      "metadata": {
        "id": "d5547404"
      },
      "outputs": [],
      "source": [
        "# Чистим записи, содержащие все пустые значения (таковых нет)\n",
        "all_models = all_models.dropna(how='all')\n",
        "# Мерджим Tax с Tax2, если у первого пропущены значения\n",
        "print(len(all_models[all_models.Tax.isna()]))\n",
        "all_models.Tax.fillna(all_models.Tax2, inplace = True)\n",
        "print(len(all_models[all_models.Tax.isna()]))\n",
        "print(all_models[all_models.Tax2.isna() != True])\n",
        "# Удаляем Tax2\n",
        "all_models = all_models.drop('Tax2', axis = 1)\n",
        "# Вычисляем возраст автомобиля\n",
        "all_models['Car_age'] = 2022 - all_models['Year']\n",
        "# Удаляем колонку года выпуска автомобиля\n",
        "all_models = all_models.drop('Year', axis = 1)\n",
        "all_models = all_models.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90ba691f",
      "metadata": {
        "id": "90ba691f"
      },
      "outputs": [],
      "source": [
        "# Удаление пробелов в тексте\n",
        "all_models['Model'] = all_models['Model'].apply(lambda x: x.strip()) \n",
        "\n",
        "# Выделение данных моделей автомобилей в класс электрических\n",
        "elec = ['Ioniq', 'i3', 'Ampera'] # перенос данных марок авто в класс электромобилей\n",
        "all_models.loc[all_models.Model.isin(elec), 'Fuel_Type'] = 'Electric'\n",
        "\n",
        "# # Проверка столбца года выпуска на битые значения\n",
        "f_year_1 = all_models.Car_age < 50\n",
        "f_year_2 = all_models.Car_age > -1\n",
        "print(f'Записей с некорректным годом выпуска : {(~f_year_1).sum(), (~f_year_2).sum()}') # ПРОВЕРКА СТОЛБЦА ГОД ВЫПУСКА НА БИТЫЕ ЗНАЧЕНИЯ\n",
        "\n",
        "f_engine = all_models.Engine_Size != 0\n",
        "print(f'Записей с некорректным объёмом двигателя : {(~f_engine).sum()}')\n",
        "\n",
        "# Электрические + некорректный объем двигателя\n",
        "# print(len(all_models[~f_engine][all_models.Fuel_Type == 'Electric']))\n",
        "\n",
        "ggg = all_models[all_models.Fuel_Type == 'Electric']\n",
        "\n",
        "f_electric = all_models.Fuel_Type == 'Electric'\n",
        "print(f'Записей электромобилей : {(f_electric).sum()}')\n",
        "\n",
        "# # Удаление битых данных\n",
        "all_models = all_models[f_year_1]\n",
        "print(len(all_models))\n",
        "all_models = all_models[f_year_2]\n",
        "print(len(all_models))\n",
        "all_models = all_models[f_engine]\n",
        "print(len(all_models))\n",
        "all_models = all_models[~f_electric]\n",
        "print(len(all_models))\n",
        "all_models.Tax = all_models.Tax.astype(int)\n",
        "print(len(all_models))\n",
        "all_models = all_models[all_models.Transmission != 'Other']\n",
        "print(len(all_models))\n",
        "all_models = all_models[all_models.Fuel_Type != 'Other']\n",
        "print(len(all_models))\n",
        "all_models = shuffle(all_models).reset_index(drop=True)\n",
        "print(len(all_models))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ce2f5d",
      "metadata": {
        "collapsed": true,
        "id": "59ce2f5d"
      },
      "outputs": [],
      "source": [
        "# Визуальный вывод данных по столбцам\n",
        "sns.set(rc = {'figure.figsize':(12,8)})\n",
        "columnNames = {\n",
        "    'Price': 'Цена',\n",
        "    'Mileage': 'Пробег',\n",
        "    'MPG': 'Расход топлива',\n",
        "    'Car_age': 'Возраст',\n",
        "    'Engine_Size': 'Объем двигателя',\n",
        "    'Tax': 'Налог',\n",
        "}\n",
        "\n",
        "for name in columnNames:\n",
        "  plt.hist(all_models[name], bins=50)\n",
        "  plt.ylabel('Количество автомобилей')\n",
        "  plt.xlabel(columnNames[name])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d754544",
      "metadata": {
        "id": "5d754544"
      },
      "outputs": [],
      "source": [
        "for i in all_models.columns: # статистика переменных типа \"объект\"\n",
        "    if all_models[i].dtype == 'O':\n",
        "        display(all_models[i].value_counts().to_frame())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Постобработка"
      ],
      "metadata": {
        "id": "Gf-g8nLiF8oJ"
      },
      "id": "Gf-g8nLiF8oJ"
    },
    {
      "cell_type": "markdown",
      "id": "e36b5b79",
      "metadata": {
        "id": "e36b5b79"
      },
      "source": [
        "### Создание dummy переменных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbba879f",
      "metadata": {
        "collapsed": true,
        "id": "fbba879f"
      },
      "outputs": [],
      "source": [
        "all_models_d = pd.get_dummies(all_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54defb01",
      "metadata": {
        "id": "54defb01"
      },
      "source": [
        "### Отбор значений с ненулевыми значениями более 1%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcbd668d",
      "metadata": {
        "collapsed": true,
        "id": "bcbd668d"
      },
      "outputs": [],
      "source": [
        "f_f1 = ((all_models_d == 0).sum()/(len(all_models_d)) < 0.99)\n",
        "all_models_d = all_models_d.loc[:, f_f1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "647ff7b4",
      "metadata": {
        "id": "647ff7b4"
      },
      "source": [
        "### Матрица корреляций и удаление мультиколлинеарных переменных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4984ce66",
      "metadata": {
        "id": "4984ce66"
      },
      "outputs": [],
      "source": [
        "sns.set(rc = {'figure.figsize':(8,6)})\n",
        "sns.heatmap(all_models_d.iloc[:, :6].corr(),\n",
        "            annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm', cbar=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae72eebc",
      "metadata": {
        "id": "ae72eebc"
      },
      "outputs": [],
      "source": [
        "df_corr = all_models_d.corr() # Определение столбцов с взаимной корреляцией больше 0,7\n",
        "df_bad = pd.DataFrame()\n",
        "for i in df_corr.columns:\n",
        "    for j in df_corr.index:\n",
        "        in_col = sorted([i, j])\n",
        "        if ((abs(df_corr.loc[in_col[0], in_col[1]]) > 0.7) & (in_col[0] != in_col[1])):\n",
        "            df_bad = df_bad.append(pd.DataFrame([in_col[0], in_col[1], df_corr.loc[in_col[0], in_col[1]]]).T)\n",
        "df_bad.columns = [0, 1, 'Value']\n",
        "df_bad = df_bad.drop_duplicates().reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ddcffd5",
      "metadata": {
        "id": "8ddcffd5"
      },
      "outputs": [],
      "source": [
        "col_to_drop = []\n",
        "for i in range(len(df_bad)): # Определяем столбец, который дает меньший вес прогноз. значению (цене)\n",
        "    x = abs(df_corr.loc['Price', [df_bad.iloc[i, 0], df_bad.iloc[i, 1]]])\n",
        "    print(1111, x)\n",
        "    print(2222, np.argmin(x))\n",
        "    # col_to_drop.append(df_bad.loc[i, np.argmin(x)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_models_d = all_models_d.drop(col_to_drop, axis=1) # Удаляем столбец, который выбрали"
      ],
      "metadata": {
        "id": "IWR11xPZ7KMa"
      },
      "id": "IWR11xPZ7KMa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8fd30da",
      "metadata": {
        "id": "b8fd30da"
      },
      "outputs": [],
      "source": [
        "def std_df(df, col): # Функция стандартизации\n",
        "    print(777, df, col)\n",
        "    var = mt.sqrt(df[col].var())\n",
        "    mean = df[col].mean()\n",
        "    print(888, (df[col] - mean) / var )\n",
        "    return (df[col] - mean) / var \n",
        "def un_std_df(df, col): # НЕ ИСПОЛЬЗУЕТСЯ\n",
        "    var = mt.sqrt(all_models[col].var())\n",
        "    mean = all_models[col].mean()\n",
        "    return (df[col] * var) + mean\n",
        "def un_std_per(per): # НЕ ИСПОЛЬЗУЕТСЯ\n",
        "    var = mt.sqrt(all_models.Price.var())\n",
        "    mean = all_models.Price.mean()\n",
        "    return (per * var) + mean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67d71bab",
      "metadata": {
        "id": "67d71bab"
      },
      "source": [
        "### Отбор переменных с корреляций больше 0,05 по модулю"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a321a63",
      "metadata": {
        "collapsed": true,
        "id": "0a321a63"
      },
      "outputs": [],
      "source": [
        "all_models_d1 = all_models_d.copy()\n",
        "\n",
        "list_corr = all_models_d.corr().iloc[:, 0] # Определяем столбцы с низкой коррреляцией чтобы потом их выкинуть\n",
        "f_f2 = (abs(list_corr) > 0.05)\n",
        "all_models_d = all_models_d.loc[:, f_f2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec0e9d54",
      "metadata": {
        "id": "ec0e9d54"
      },
      "source": [
        "### Стандартизация переменных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f0dc715",
      "metadata": {
        "collapsed": true,
        "id": "2f0dc715"
      },
      "outputs": [],
      "source": [
        "colls = ['Mileage', 'Tax', 'MPG', 'Engine_Size', 'Car_age']\n",
        "all_models_d_std = all_models_d.copy()\n",
        "for i in colls:\n",
        "    try:\n",
        "      all_models.var()\n",
        "        all_models_d_std[i] = std_df(all_models_d, i)\n",
        "    except: pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_models_d_std # Вывод финальной таблицы с которой мы пойдем в нейронку"
      ],
      "metadata": {
        "id": "TAeiL8_xLgC0"
      },
      "id": "TAeiL8_xLgC0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6defc271",
      "metadata": {
        "id": "6defc271"
      },
      "source": [
        "# Построение нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_models_d_std = all_models_d_std[:5000] #для проверки"
      ],
      "metadata": {
        "id": "M71ImpqJVrdC"
      },
      "id": "M71ImpqJVrdC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(y_pred, y_test):\n",
        "    \"\"\"\n",
        "      Принимает на вход предсказанные значения y и тестовые значения y\n",
        "      Возвращает массив:\n",
        "        0: R2 - Коэффициент детерминации\n",
        "        1: MAE - средняя абсолютная ошибка\n",
        "        2: RMSE - среднеквадратичная ошибка\n",
        "        3: MAPE - средняя абсолютная ошибка. В среднем ошибаемся на MAPE %\n",
        "    \"\"\"\n",
        "    # Получаем коэффициент детерминации и округляем до 5 знаков\n",
        "    R2 = round(r2_score(list(y_test), y_pred), 5)\n",
        "    # Вычисление средней абсолютной ошибки\n",
        "    MAE = int(mean_absolute_error(list(y_test), y_pred))\n",
        "    # Вычисление среднеквадратичной ошибки\n",
        "    RMSE = int(mean_squared_error(list(y_test), y_pred, squared=False))\n",
        "    # Вычисление средней абсолютной ошибки в процентах и округление до 5 знаков\n",
        "    MAPE = round(mean_absolute_percentage_error(list(y_test), y_pred), 5)\n",
        "\n",
        "    return [R2, MAE, RMSE, MAPE]"
      ],
      "metadata": {
        "id": "G9KNV57C7bNI"
      },
      "id": "G9KNV57C7bNI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_x = len(list(X_test))\n",
        "len_y = 1\n",
        "def baseline_model():\n",
        "\t\"\"\"\n",
        "\t\tВозвращает нейронную сеть из 6 слоев:\n",
        "\t\t\t1: Входной слой размерности 5/4 * dataset_length. Экспоненциальная функция активации\n",
        "\t\t\t2: Скрытый слой размерности dataset_length. Сигмоидная функция активации\n",
        "\t\t\t3: Скрытый слой размерности 3/4 * dataset_length. ReLu функция активации\n",
        "\t\t\t4: Скрытый слой размерности 2/4 * dataset_length. ReLu функция активации\n",
        "\t\t\t5: Скрытый слой размерности 1/4 * dataset_length. ReLu функция активации\n",
        "\t\t\t6: Выходной слой размерности 1. Линейная функция активации\n",
        "\t\"\"\"\n",
        "\t# Создаем sequential модель через библиотеку keras\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\t# Добавление слоев.\n",
        "\t# Количество нейронов = (длина выборки * (5 - i)) / 4,\n",
        "\t# где i - порядковый номер слоя\n",
        "\n",
        "\t# Входной слой\n",
        "\t# Передаем размер входного слоя input_dim = размеру X-тестовой выборки. В качестве функции активации - экспоненциальная.\n",
        "\tmodel.add(Dense(5*len_x/4, input_dim=len_x, kernel_initializer='normal', activation='exponential'))\n",
        " \n",
        "\t# Скрытые слои\n",
        "\t# Передаем сигмоидную функцию активации. A = (1 / (1 + e^(-x)))\n",
        "\tmodel.add(Dense(4*len_x/4, kernel_initializer='normal', activation='sigmoid'))\n",
        " \n",
        "\t# Передаем ReLu функцию активации. A(x) = max(0, x)\n",
        "\tmodel.add(Dense(3*len_x/4, kernel_initializer='normal', activation='relu')) #линейная\n",
        "\tmodel.add(Dense(2*len_x/4, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(len_x/4, kernel_initializer='normal', activation='relu'))\n",
        " \n",
        "\t# Выходной слой\n",
        "\t# Размерность = 1. По умолчанию в качестве функции активации - линейная\n",
        "\tmodel.add(Dense(len_y, kernel_initializer='normal'))\n",
        "\t\n",
        "\t# Настройка модели для обучения.\n",
        "\t# В качестве функции потери - MSE, среднеквадратичная ошибка\n",
        "\t# В качестве оптимизатора - алгоритм Адама\n",
        "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
        " \treturn model\n",
        "\n",
        "# Указываем число для рандомизации random_state\n",
        "seed = 322\n",
        "# Количество эпох обучения\n",
        "epochs = 5\n",
        "# Количество выборок для обновления градиента (для подгонки и прогнозирования)\n",
        "batch_size = 2\n",
        "\n",
        "# Для регрессионной оценки использован KerasRegressor\n",
        "estimator = KerasRegressor(build_fn=baseline_model, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "# Проверка модели через cross-валидатор KFold.\n",
        "# Переменная принимает индексы из тренировочных и тестовых выборок\n",
        "kfold = KFold(n_splits=5, random_state=seed, shuffle=True)\n",
        "\n",
        "# X - все столбцы, за исключением столбка цен\n",
        "# y - столбец цен\n",
        "X, y = all_models_d_std.drop(columns = ['Price']), all_models_d_std['Price']\n",
        "\n",
        "predicts = []\n",
        "for train_index, test_index in kfold.split(X):\n",
        "\t\tprint(len(train_index), len(test_index))\n",
        "\t\t# Получение тренировочной и тестовой выборок из оригинального датафрейма\n",
        "\t\tX_train, X_test = X.loc[train_index, :], X.loc[test_index, :]\n",
        "\t\ty_train, y_test = y[train_index], y[test_index]\n",
        "\t\t# Подгонка модели\n",
        "\t\testimator.fit(X_train, y_train)\n",
        "\t\t# Прогноз на тестовой выборке данных\n",
        "\t\tprediction = estimator.predict(X_test)\n",
        "\t\t# Добавляем текущий прогноз в массив\n",
        "\t\tpredicts.append(prediction)\n",
        "\t\t# Вывод R2, MAE, RMSE, MAPE\n",
        "\t\tprint(get_score(prediction, y_test))"
      ],
      "metadata": {
        "id": "1pzRjc4651ZH"
      },
      "id": "1pzRjc4651ZH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eIPZu4-c3MIO",
        "LU1ey1VyEMzd",
        "Gf-g8nLiF8oJ",
        "TqGQLMh5-vy4"
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}